{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Theoretical Questions\n",
        "\n",
        "Q.\t1 Can we use Bagging for regression problems?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "Yes, Bagging can be used for regression problems by employing regressors like DecisionTreeRegressor as base estimators. It reduces variance and helps avoid overfitting.\n",
        "\n",
        "Q.\t2. What is the difference between multiple model training and single model training?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "Single model training uses one algorithm to make predictions. Multiple model training involves combining the outputs of several models to improve performance, reduce overfitting, and increase robustness.\n",
        "\n",
        "Q.\t3. Explain the concept of feature randomness in Random Forest.\n",
        "\n",
        "Answer :-\n",
        "\n",
        "In Random Forest, each tree considers only a random subset of features when splitting nodes. This feature randomness decorrelates trees, improving ensemble performance.\n",
        "\n",
        "Q.\t4. What is OOB (Out-of-Bag) Score?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "OOB score is an internal validation score for Bagging and Random Forest models. It estimates accuracy using only the samples not included in each bootstrap sample.\n",
        "\n",
        "Q. 5. How can you measure the importance of features in a Random Forest model?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "Feature importance can be measured by the mean decrease in impurity (Gini or entropy) or permutation importance, showing how much each feature contributes to the model.\n",
        "\n",
        "Q. 6. Explain the working principle of a Bagging Classifier.\n",
        "\n",
        "Answer :-\n",
        "\n",
        "Bagging Classifier builds multiple base classifiers on different bootstrap samples and aggregates their predictions (majority voting) to improve generalization.\n",
        "\n",
        "Q.\t7. How do you evaluate a Bagging Classifier’s performance?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "It can be evaluated using accuracy, confusion matrix, precision, recall, F1-score, or ROC-AUC on test data or OOB samples.\n",
        "\n",
        "Q.\t8.  How does a Bagging Regressor work?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "Similar to the classifier, Bagging Regressor trains multiple regressors on bootstrap samples and averages their outputs for final prediction.\n",
        "\n",
        "Q. 9. What is the main advantage of ensemble techniques?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "Ensemble techniques improve accuracy and generalization by combining multiple models, reducing variance and/or bias.\n",
        "\n",
        "Q.\t10. What is the main challenge of ensemble methods?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "They increase model complexity, are computationally expensive, and can be harder to interpret compared to single models.\n",
        "\n",
        "Q.\t11. Explain the key idea behind ensemble techniques.\n",
        "\n",
        "Answer :-\n",
        "\n",
        "Ensemble learning combines multiple models to produce a more accurate and stable prediction than any individual model.\n",
        "\n",
        "Q.\t12. What is a Random Forest Classifier?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "A Random Forest Classifier is an ensemble of Decision Trees built using bagging and feature randomness to improve classification accuracy.\n",
        "\n",
        "Q.\t13. What are the main types of ensemble techniques?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "•\tBagging\n",
        "•\tBoosting\n",
        "•\tStacking\n",
        "\n",
        "Q.\t14. What is ensemble learning in machine learning?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "It is a technique where multiple models are trained and combined to solve a particular problem, aiming to achieve better performance.\n",
        "\n",
        "Q.\t15. When should we avoid using ensemble methods?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "When interpretability and low computational cost are priorities, or when data is too small to benefit from ensemble techniques.\n",
        "\n",
        "Q.\t16. How does Bagging help in reducing overfitting?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "By averaging multiple models trained on different bootstrap samples, Bagging reduces variance and thus overfitting.\n",
        "\n",
        "Q.17. Why is Random Forest better than a single Decision Tree?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "It combines multiple trees to reduce overfitting, increase robustness, and improve accuracy.\n",
        "\n",
        "Q.\t18. What is the role of bootstrap sampling in Bagging?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "Bootstrap sampling provides diversity by training each base model on a randomly sampled subset (with replacement) of the training data.\n",
        "\n",
        "\n",
        "Q.\t19. What are some real-world applications of ensemble techniques?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "•\tFraud detection\n",
        "•\tCredit scoring\n",
        "•\tMedical diagnosis\n",
        "•\tStock market prediction\n",
        "•\tCustomer churn prediction\n",
        "\n",
        "Q.\t20.  What is the difference between Bagging and Boosting?\n",
        "\n",
        "Answer :-\n",
        "\n",
        "•\tBagging: Reduces variance; trains models in parallel; uses bootstrap sampling.\n",
        "•\tBoosting: Reduces bias; trains models sequentially; focuses on correcting previous errors.\n"
      ],
      "metadata": {
        "id": "JXBpTyCJzBZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical Questions"
      ],
      "metadata": {
        "id": "2HQrpoyFCIJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier with Decision Trees\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the classifier\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0maZO9XmCOIF",
        "outputId": "279a1c0f-e15f-43ad-a950-1a314425015c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q. 22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target (median house value)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Regressor as the base estimator\n",
        "base_dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Initialize the Bagging Regressor\n",
        "bagging_reg = BaggingRegressor(\n",
        "    estimator=base_dt,\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "bagging_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging_reg.predict(X_test)\n",
        "\n",
        "# Calculate and print Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE) of Bagging Regressor: {mse:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hwrOdniDXvI",
        "outputId": "973d9be1-8a68-4cc1-921e-ebc418ab6bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) of Bagging Regressor: 0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "feature_names = data.feature_names  # Feature names\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance scores\n",
        "feature_importances = rf_clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature names and their importance scores\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort by importance in descending order\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print feature importance scores\n",
        "print(\"Feature Importance Scores:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH6gSi98Dy1N",
        "outputId": "d1c4ca92-c4a2-4e63-a7d7-a5d637d5490d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "                    Feature  Importance\n",
            "23               worst area    0.153892\n",
            "27     worst concave points    0.144663\n",
            "7       mean concave points    0.106210\n",
            "20             worst radius    0.077987\n",
            "6            mean concavity    0.068001\n",
            "22          worst perimeter    0.067115\n",
            "2            mean perimeter    0.053270\n",
            "0               mean radius    0.048703\n",
            "3                 mean area    0.047555\n",
            "26          worst concavity    0.031802\n",
            "13               area error    0.022407\n",
            "21            worst texture    0.021749\n",
            "25        worst compactness    0.020266\n",
            "10             radius error    0.020139\n",
            "5          mean compactness    0.013944\n",
            "1              mean texture    0.013591\n",
            "12          perimeter error    0.011303\n",
            "24         worst smoothness    0.010644\n",
            "28           worst symmetry    0.010120\n",
            "16          concavity error    0.009386\n",
            "4           mean smoothness    0.007285\n",
            "19  fractal dimension error    0.005321\n",
            "15        compactness error    0.005253\n",
            "29  worst fractal dimension    0.005210\n",
            "11            texture error    0.004724\n",
            "14         smoothness error    0.004271\n",
            "18           symmetry error    0.004018\n",
            "9    mean fractal dimension    0.003886\n",
            "8             mean symmetry    0.003770\n",
            "17     concave points error    0.003513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t24. Train a Random Forest Regressor and compare its performance with a single Decision Tree.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target (median house value)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a single Decision Tree Regressor\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Decision Tree\n",
        "dt_pred = dt_reg.predict(X_test)\n",
        "dt_mse = mean_squared_error(y_test, dt_pred)\n",
        "\n",
        "# Initialize and train a Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Random Forest\n",
        "rf_pred = rf_reg.predict(X_test)\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "\n",
        "# Print performance comparison\n",
        "print(\"Performance Comparison:\")\n",
        "print(f\"Decision Tree Regressor MSE: {dt_mse:.2f}\")\n",
        "print(f\"Random Forest Regressor MSE: {rf_mse:.2f}\")\n",
        "print(f\"MSE Improvement (DT - RF): {dt_mse - rf_mse:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfHHPdH5D857",
        "outputId": "04e88284-0cf8-4ffd-c225-b144f4b5bc73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Comparison:\n",
            "Decision Tree Regressor MSE: 0.50\n",
            "Random Forest Regressor MSE: 0.26\n",
            "MSE Improvement (DT - RF): 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Classifier with OOB score enabled\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get the OOB score\n",
        "oob_score = rf_clf.oob_score_\n",
        "\n",
        "# Print the OOB score\n",
        "print(f\"Out-of-Bag (OOB) Score: {oob_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apgAcg2uEWQM",
        "outputId": "0fc70672-29ce-48f2-a417-fcb37903cd1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-Bag (OOB) Score: 0.9560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t26. Train a Bagging Classifier using SVM as a base estimator and print accuracy.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the SVM as the base estimator\n",
        "base_svm = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier with SVM\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=base_svm,\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the classifier\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of Bagging Classifier with SVM: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhnAzFbwEmwW",
        "outputId": "d263a7b4-3e04-488c-cdfa-63b89d75388b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Bagging Classifier with SVM: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t27. Train a Random Forest Classifier with different numbers of trees and compare accuracy.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define different numbers of trees to test\n",
        "n_estimators_list = [10, 50, 100, 200, 500]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Train and evaluate Random Forest for each number of trees\n",
        "for n in n_estimators_list:\n",
        "    # Initialize the Random Forest Classifier\n",
        "    rf_clf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "\n",
        "    # Train the classifier\n",
        "    rf_clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    results.append({'n_estimators': n, 'Accuracy': accuracy})\n",
        "\n",
        "# Create a DataFrame to display results\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Print the comparison table\n",
        "print(\"Accuracy Comparison for Different Numbers of Trees:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xpA-YgjEx0G",
        "outputId": "00e8bbb6-52d7-4184-be91-11ff6ad33d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison for Different Numbers of Trees:\n",
            "   n_estimators  Accuracy\n",
            "0            10  0.956140\n",
            "1            50  0.964912\n",
            "2           100  0.964912\n",
            "3           200  0.964912\n",
            "4           500  0.964912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC scores.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Logistic Regression as the base estimator\n",
        "base_lr = LogisticRegression(random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier with Logistic Regression\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=base_lr,\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the classifier\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for AUC calculation\n",
        "y_pred_proba = bagging_clf.predict_proba(X_test)[:, 1]  # Probability for positive class (benign)\n",
        "\n",
        "# Calculate and print AUC score\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"AUC Score of Bagging Classifier with Logistic Regression: {auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXiY09xPFAOS",
        "outputId": "f0f86cea-778d-42fe-85fc-902b391c3d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score of Bagging Classifier with Logistic Regression: 0.9964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t29. Train a Random Forest Regressor and analyze feature importance scores.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target (median house value)\n",
        "feature_names = data.feature_names  # Feature names\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance scores\n",
        "feature_importances = rf_reg.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature names and their importance scores\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort by importance in descending order\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print feature importance scores\n",
        "print(\"Feature Importance Scores:\")\n",
        "print(importance_df)\n",
        "\n",
        "# Optional: Print basic analysis\n",
        "print(\"\\nAnalysis:\")\n",
        "print(f\"Most important feature: {importance_df.iloc[0]['Feature']} (Importance: {importance_df.iloc[0]['Importance']:.4f})\")\n",
        "print(f\"Least important feature: {importance_df.iloc[-1]['Feature']} (Importance: {importance_df.iloc[-1]['Importance']:.4f})\")\n",
        "print(f\"Top 3 features contribute {importance_df['Importance'].iloc[:3].sum():.4f} of total importance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha3Pf7rgFMcN",
        "outputId": "7f3646be-f8c8-4776-ba68-cebc953d8a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "      Feature  Importance\n",
            "0      MedInc    0.524871\n",
            "5    AveOccup    0.138443\n",
            "6    Latitude    0.088936\n",
            "7   Longitude    0.088629\n",
            "1    HouseAge    0.054593\n",
            "2    AveRooms    0.044272\n",
            "4  Population    0.030650\n",
            "3   AveBedrms    0.029606\n",
            "\n",
            "Analysis:\n",
            "Most important feature: MedInc (Importance: 0.5249)\n",
            "Least important feature: AveBedrms (Importance: 0.0296)\n",
            "Top 3 features contribute 0.7523 of total importance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier with Decision Trees\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the Bagging Classifier\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with Bagging Classifier\n",
        "bagging_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for Bagging Classifier\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with Random Forest Classifier\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for Random Forest Classifier\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "# Create a DataFrame to compare accuracies\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['Bagging Classifier', 'Random Forest Classifier'],\n",
        "    'Accuracy': [bagging_accuracy, rf_accuracy]\n",
        "})\n",
        "\n",
        "# Print the comparison table\n",
        "print(\"Accuracy Comparison:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm2rxuw0FcNZ",
        "outputId": "88ee1b1d-2e30-4535-a7d6-ec775f47bc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison:\n",
            "                      Model  Accuracy\n",
            "0        Bagging Classifier  0.956140\n",
            "1  Random Forest Classifier  0.964912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_clf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set with the best model\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the best hyperparameters and accuracy\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(f\"Accuracy of Best Random Forest Classifier: {accuracy:.4f}\")\n",
        "\n",
        "# Optional: Display top 5 parameter combinations\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "top_results = results[['params', 'mean_test_score', 'std_test_score']].sort_values(by='mean_test_score', ascending=False).head(5)\n",
        "print(\"\\nTop 5 Parameter Combinations:\")\n",
        "print(top_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8q4BsPlFr4e",
        "outputId": "ae62aa2a-ca72-41d9-cb4a-1449d0aa7a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Accuracy of Best Random Forest Classifier: 0.9649\n",
            "\n",
            "Top 5 Parameter Combinations:\n",
            "                                               params  mean_test_score  \\\n",
            "2   {'max_depth': None, 'min_samples_leaf': 1, 'mi...         0.962637   \n",
            "56  {'max_depth': 20, 'min_samples_leaf': 1, 'min_...         0.962637   \n",
            "29  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...         0.962637   \n",
            "13  {'max_depth': None, 'min_samples_leaf': 2, 'mi...         0.958242   \n",
            "1   {'max_depth': None, 'min_samples_leaf': 1, 'mi...         0.958242   \n",
            "\n",
            "    std_test_score  \n",
            "2         0.013187  \n",
            "56        0.013187  \n",
            "29        0.013187  \n",
            "13        0.012815  \n",
            "1         0.017582  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t32. Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target (median house value)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define different numbers of base estimators to test\n",
        "n_estimators_list = [10, 50, 100, 200, 500]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Train and evaluate Bagging Regressor for each number of estimators\n",
        "for n in n_estimators_list:\n",
        "    # Initialize the Bagging Regressor with Decision Trees\n",
        "    bagging_reg = BaggingRegressor(\n",
        "        estimator=DecisionTreeRegressor(random_state=42),\n",
        "        n_estimators=n,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Train the regressor\n",
        "    bagging_reg.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = bagging_reg.predict(X_test)\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    results.append({'n_estimators': n, 'MSE': mse})\n",
        "\n",
        "# Create a DataFrame to display results\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Print the comparison table\n",
        "print(\"Performance Comparison (MSE) for Different Numbers of Base Estimators:\")\n",
        "print(results_df)\n",
        "\n",
        "# Optional: Print analysis\n",
        "print(\"\\nAnalysis:\")\n",
        "print(f\"Best MSE: {results_df['MSE'].min():.4f} (n_estimators={results_df.loc[results_df['MSE'].idxmin(), 'n_estimators']})\")\n",
        "print(f\"Worst MSE: {results_df['MSE'].max():.4f} (n_estimators={results_df.loc[results_df['MSE'].idxmax(), 'n_estimators']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwZx8rR7F3Ae",
        "outputId": "3ff5dc64-83f8-4bb2-e8a7-7ea9ba792064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Comparison (MSE) for Different Numbers of Base Estimators:\n",
            "   n_estimators       MSE\n",
            "0            10  0.282424\n",
            "1            50  0.257299\n",
            "2           100  0.255924\n",
            "3           200  0.254093\n",
            "4           500  0.252442\n",
            "\n",
            "Analysis:\n",
            "Best MSE: 0.2524 (n_estimators=500)\n",
            "Worst MSE: 0.2824 (n_estimators=10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t33. Train a Random Forest Classifier and analyze misclassified samples.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "feature_names = data.feature_names  # Feature names\n",
        "target_names = data.target_names  # Target names (malignant, benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of Random Forest Classifier: {accuracy:.4f}\")\n",
        "\n",
        "# Identify misclassified samples\n",
        "misclassified_indices = np.where(y_test != y_pred)[0]\n",
        "\n",
        "# Create a DataFrame to store misclassified samples\n",
        "misclassified_data = []\n",
        "\n",
        "for idx in misclassified_indices:\n",
        "    misclassified_data.append({\n",
        "        'Index': idx,\n",
        "        'True Label': target_names[y_test[idx]],\n",
        "        'Predicted Label': target_names[y_pred[idx]],\n",
        "        **{feature_names[i]: X_test[idx, i] for i in range(X_test.shape[1])}\n",
        "    })\n",
        "\n",
        "misclassified_df = pd.DataFrame(misclassified_data)\n",
        "\n",
        "# Print analysis of misclassified samples\n",
        "print(\"\\nAnalysis of Misclassified Samples:\")\n",
        "if not misclassified_df.empty:\n",
        "    print(f\"Number of misclassified samples: {len(misclassified_df)}\")\n",
        "    print(\"\\nMisclassified Samples Details:\")\n",
        "    print(misclassified_df)\n",
        "else:\n",
        "    print(\"No misclassified samples found.\")\n",
        "\n",
        "# Optional: Summary statistics of misclassified vs. all test samples for key features\n",
        "if not misclassified_df.empty:\n",
        "    key_features = feature_names[:5]  # Analyze first 5 features for brevity\n",
        "    print(\"\\nSummary Statistics Comparison (Misclassified vs. All Test Samples):\")\n",
        "    for feature in key_features:\n",
        "        misclassified_values = misclassified_df[feature].values\n",
        "        all_test_values = X_test[:, np.where(feature_names == feature)[0][0]]\n",
        "        print(f\"\\n{feature}:\")\n",
        "        print(f\"  Misclassified - Mean: {np.mean(misclassified_values):.4f}, Std: {np.std(misclassified_values):.4f}\")\n",
        "        print(f\"  All Test      - Mean: {np.mean(all_test_values):.4f}, Std: {np.std(all_test_values):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we69j3e_GAzM",
        "outputId": "a0cfaa2d-0c0a-489f-99a7-23045638db80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Random Forest Classifier: 0.9649\n",
            "\n",
            "Analysis of Misclassified Samples:\n",
            "Number of misclassified samples: 4\n",
            "\n",
            "Misclassified Samples Details:\n",
            "   Index True Label Predicted Label  mean radius  mean texture  \\\n",
            "0      8     benign       malignant        13.34         15.86   \n",
            "1     20  malignant          benign        13.80         15.79   \n",
            "2     77  malignant          benign        13.96         17.05   \n",
            "3     82  malignant          benign        14.48         21.46   \n",
            "\n",
            "   mean perimeter  mean area  mean smoothness  mean compactness  \\\n",
            "0           86.49      520.0          0.10780           0.15350   \n",
            "1           90.43      584.1          0.10070           0.12800   \n",
            "2           91.43      602.4          0.10960           0.12790   \n",
            "3           94.25      648.2          0.09444           0.09947   \n",
            "\n",
            "   mean concavity  ...  worst radius  worst texture  worst perimeter  \\\n",
            "0         0.11690  ...         15.53          23.19            96.66   \n",
            "1         0.07789  ...         16.57          20.86           110.30   \n",
            "2         0.09789  ...         16.39          22.07           108.10   \n",
            "3         0.12040  ...         16.21          29.25           108.40   \n",
            "\n",
            "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
            "0       614.9            0.1536             0.4791           0.4858   \n",
            "1       812.4            0.1411             0.3542           0.2779   \n",
            "2       826.0            0.1512             0.3262           0.3209   \n",
            "3       808.9            0.1306             0.1976           0.3349   \n",
            "\n",
            "   worst concave points  worst symmetry  worst fractal dimension  \n",
            "0                0.1708          0.3527                  0.10160  \n",
            "1                0.1383          0.2589                  0.10300  \n",
            "2                0.1374          0.3068                  0.07957  \n",
            "3                0.1225          0.3020                  0.06846  \n",
            "\n",
            "[4 rows x 33 columns]\n",
            "\n",
            "Summary Statistics Comparison (Misclassified vs. All Test Samples):\n",
            "\n",
            "mean radius:\n",
            "  Misclassified - Mean: 13.8950, Std: 0.4073\n",
            "  All Test      - Mean: 14.1658, Std: 3.4765\n",
            "\n",
            "mean texture:\n",
            "  Misclassified - Mean: 17.5400, Std: 2.3179\n",
            "  All Test      - Mean: 19.7072, Std: 4.4132\n",
            "\n",
            "mean perimeter:\n",
            "  Misclassified - Mean: 90.6500, Std: 2.7804\n",
            "  All Test      - Mean: 92.3154, Std: 24.2039\n",
            "\n",
            "mean area:\n",
            "  Misclassified - Mean: 588.6750, Std: 46.0130\n",
            "  All Test      - Mean: 656.9307, Std: 339.5754\n",
            "\n",
            "mean smoothness:\n",
            "  Misclassified - Mean: 0.1031, Std: 0.0060\n",
            "  All Test      - Mean: 0.0988, Std: 0.0144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a single Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with Decision Tree\n",
        "dt_pred = dt_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for Decision Tree\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "\n",
        "# Initialize and train the Bagging Classifier with Decision Trees\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with Bagging Classifier\n",
        "bagging_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for Bagging Classifier\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
        "\n",
        "# Create a DataFrame to compare accuracies\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['Decision Tree Classifier', 'Bagging Classifier'],\n",
        "    'Accuracy': [dt_accuracy, bagging_accuracy]\n",
        "})\n",
        "\n",
        "# Print the comparison table\n",
        "print(\"Performance Comparison (Accuracy):\")\n",
        "print(results_df)\n",
        "\n",
        "# Optional: Print improvement\n",
        "print(f\"\\nAccuracy Improvement (Bagging - DT): {bagging_accuracy - dt_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtQdtpzOGLoj",
        "outputId": "dc3c7a7a-1a13-4687-eb72-6c792fe0407c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Comparison (Accuracy):\n",
            "                      Model  Accuracy\n",
            "0  Decision Tree Classifier  0.947368\n",
            "1        Bagging Classifier  0.956140\n",
            "\n",
            "Accuracy Improvement (Bagging - DT): 0.0088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t35. Train a Random Forest Classifier and visualize the confusion matrix.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "target_names = data.target_names  # Target names (malignant, benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of Random Forest Classifier: {accuracy:.4f}\")\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot (optional, comment out if not needed)\n",
        "plt.savefig('confusion_matrix.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "j6CmgubZGg8Y",
        "outputId": "a9375c62-9d7e-42b0-db0a-2fdbe06ddd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Random Forest Classifier: 0.9649\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for SVM and Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize base learners\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "svm_clf = SVC(probability=True, random_state=42)  # probability=True for stacking\n",
        "lr_clf = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train and evaluate individual base learners\n",
        "classifiers = {\n",
        "    'Decision Tree': dt_clf,\n",
        "    'SVM': svm_clf,\n",
        "    'Logistic Regression': lr_clf\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "# Evaluate individual classifiers\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'Model': name, 'Accuracy': accuracy})\n",
        "\n",
        "# Initialize the Stacking Classifier\n",
        "estimators = [\n",
        "    ('dt', dt_clf),\n",
        "    ('svm', svm_clf),\n",
        "    ('lr', lr_clf)\n",
        "]\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(random_state=42),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Train the Stacking Classifier\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with Stacking Classifier\n",
        "stacking_pred = stacking_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for Stacking Classifier\n",
        "stacking_accuracy = accuracy_score(y_test, stacking_pred)\n",
        "results.append({'Model': 'Stacking Classifier', 'Accuracy': stacking_accuracy})\n",
        "\n",
        "# Create a DataFrame to compare accuracies\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Print the comparison table\n",
        "print(\"Accuracy Comparison:\")\n",
        "print(results_df)\n",
        "\n",
        "# Optional: Print the best performing model\n",
        "print(f\"\\nBest Model: {results_df.loc[results_df['Accuracy'].idxmax(), 'Model']} \"\n",
        "      f\"(Accuracy: {results_df['Accuracy'].max():.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-0HO5msGr2M",
        "outputId": "42521002-7875-45e5-9332-787438ed338f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison:\n",
            "                 Model  Accuracy\n",
            "0        Decision Tree  0.947368\n",
            "1                  SVM  0.982456\n",
            "2  Logistic Regression  0.973684\n",
            "3  Stacking Classifier  0.973684\n",
            "\n",
            "Best Model: SVM (Accuracy: 0.9825)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t37. Train a Random Forest Classifier and print the top 5 most important features.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame for feature importance\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# Sort by importance and display top 5\n",
        "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(5)\n",
        "print(\"Top 5 Important Features:\")\n",
        "print(top_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLobVIX5G3Os",
        "outputId": "0a384040-10b5-43f6-fca0-f41a8e8c30d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Important Features:\n",
            "             Feature  Importance\n",
            "2  petal length (cm)    0.439994\n",
            "3   petal width (cm)    0.421522\n",
            "0  sepal length (cm)    0.108098\n",
            "1   sepal width (cm)    0.030387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier with Decision Trees as base estimator\n",
        "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(),\n",
        "                           n_estimators=10,\n",
        "                           random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "bagging.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print results\n",
        "print(f\"Precision (weighted): {precision:.4f}\")\n",
        "print(f\"Recall (weighted): {recall:.4f}\")\n",
        "print(f\"F1-score (weighted): {f1:.4f}\")\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPq9vDWMHXD9",
        "outputId": "61a27dfc-7bfc-40f0-fd24-f9e351308a6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (weighted): 0.9561\n",
            "Recall (weighted): 0.9561\n",
            "F1-score (weighted): 0.9560\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.95      0.93      0.94        43\n",
            "      benign       0.96      0.97      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Range of max_depth values to test\n",
        "depth_values = range(1, 6)\n",
        "accuracies = []\n",
        "\n",
        "# Train and evaluate Random Forest for different max_depth values\n",
        "for depth in depth_values:\n",
        "    rf = RandomForestClassifier(max_depth=depth, n_estimators=100, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(acc)\n",
        "    print(f\"max_depth = {depth}, Accuracy = {acc:.2f}\")\n",
        "\n",
        "# Plot results\n",
        "plt.plot(depth_values, accuracies, marker='o', linestyle='--')\n",
        "plt.title('Effect of max_depth on Random Forest Accuracy')\n",
        "plt.xlabel('max_depth')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "83miFiXiHgO1",
        "outputId": "f7dc2618-6b88-4c99-867a-8d1e28a5d6c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth = 1, Accuracy = 1.00\n",
            "max_depth = 2, Accuracy = 1.00\n",
            "max_depth = 3, Accuracy = 1.00\n",
            "max_depth = 4, Accuracy = 1.00\n",
            "max_depth = 5, Accuracy = 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Load the Diabetes dataset\n",
        "data = load_diabetes()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize base estimators\n",
        "dt_base = DecisionTreeRegressor(random_state=42)\n",
        "knn_base = KNeighborsRegressor()\n",
        "\n",
        "# Initialize Bagging Regressors with different base estimators\n",
        "bagging_dt = BaggingRegressor(estimator=dt_base, n_estimators=10, random_state=42)\n",
        "bagging_knn = BaggingRegressor(estimator=knn_base, n_estimators=10, random_state=42)\n",
        "\n",
        "# Train both models\n",
        "bagging_dt.fit(X_train, y_train)\n",
        "bagging_knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_dt = bagging_dt.predict(X_test)\n",
        "y_pred_knn = bagging_knn.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "metrics = {\n",
        "    'DecisionTree': {\n",
        "        'MSE': mean_squared_error(y_test, y_pred_dt),\n",
        "        'MAE': mean_absolute_error(y_test, y_pred_dt),\n",
        "        'R2': r2_score(y_test, y_pred_dt)\n",
        "    },\n",
        "    'KNeighbors': {\n",
        "        'MSE': mean_squared_error(y_test, y_pred_knn),\n",
        "        'MAE': mean_absolute_error(y_test, y_pred_knn),\n",
        "        'R2': r2_score(y_test, y_pred_knn)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Print results\n",
        "print(\"Performance Comparison of Bagging Regressors:\")\n",
        "print(\"\\nBagging with DecisionTreeRegressor:\")\n",
        "print(f\"MSE: {metrics['DecisionTree']['MSE']:.4f}\")\n",
        "print(f\"MAE: {metrics['DecisionTree']['MAE']:.4f}\")\n",
        "print(f\"R2 Score: {metrics['DecisionTree']['R2']:.4f}\")\n",
        "\n",
        "print(\"\\nBagging with KNeighborsRegressor:\")\n",
        "print(f\"MSE: {metrics['KNeighbors']['MSE']:.4f}\")\n",
        "print(f\"MAE: {metrics['KNeighbors']['MAE']:.4f}\")\n",
        "print(f\"R2 Score: {metrics['KNeighbors']['R2']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_svfqJACIYZB",
        "outputId": "2fd08688-d55e-45fa-c5a7-9c03c9bc6f34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Comparison of Bagging Regressors:\n",
            "\n",
            "Bagging with DecisionTreeRegressor:\n",
            "MSE: 3256.9618\n",
            "MAE: 46.1326\n",
            "R2 Score: 0.3853\n",
            "\n",
            "Bagging with KNeighborsRegressor:\n",
            "MSE: 2990.6536\n",
            "MAE: 41.8591\n",
            "R2 Score: 0.4355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class\n",
        "y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC-AUC Score\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRiXYIWFI-M7",
        "outputId": "fd8ea4b5-7ef4-4121-ba2c-1dbdc5bbea12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Q.\t42. Train a Bagging Classifier and evaluate its performance using cross-validation.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier with Decision Trees as base estimator\n",
        "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(),\n",
        "                           n_estimators=10,\n",
        "                           random_state=42)\n",
        "\n",
        "# Perform 5-fold cross-validation on the training set\n",
        "cv_scores = cross_val_score(bagging, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Train the classifier on the full training set\n",
        "bagging.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging.predict(X_test)\n",
        "\n",
        "# Print cross-validation results\n",
        "print(\"5-Fold Cross-Validation Results:\")\n",
        "print(f\"Accuracy Scores per Fold: {cv_scores}\")\n",
        "print(f\"Mean CV Accuracy: {np.mean(cv_scores):.4f}\")\n",
        "print(f\"Standard Deviation: {np.std(cv_scores):.4f}\")\n",
        "\n",
        "# Print detailed classification report for test set\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9IN_egGJLi6",
        "outputId": "bd067422-06a3-4eea-a6a5-097283e83fb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-Fold Cross-Validation Results:\n",
            "Accuracy Scores per Fold: [0.94505495 0.91208791 0.94505495 0.95604396 0.92307692]\n",
            "Mean CV Accuracy: 0.9363\n",
            "Standard Deviation: 0.0162\n",
            "\n",
            "Test Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.95      0.93      0.94        43\n",
            "      benign       0.96      0.97      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t43. Train a Random Forest Classifier and plot the Precision-Recall curve.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_scores = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Plot the Precision-Recall Curve\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "disp.plot()\n",
        "plt.title(\"Precision-Recall Curve - Random Forest\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "uZa1Mk-zJVF8",
        "outputId": "399e17c3-3bd3-4edb-8662-df2f77deb258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Base learners\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Stacking Classifier (meta-learner is Logistic Regression)\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=[('rf', rf), ('lr', lr)],\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Train and evaluate individual models\n",
        "rf.fit(X_train, y_train)\n",
        "lr.fit(X_train, y_train)\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "rf_pred = rf.predict(X_test)\n",
        "lr_pred = lr.predict(X_test)\n",
        "stack_pred = stack_model.predict(X_test)\n",
        "\n",
        "# Accuracy scores\n",
        "rf_acc = accuracy_score(y_test, rf_pred)\n",
        "lr_acc = accuracy_score(y_test, lr_pred)\n",
        "stack_acc = accuracy_score(y_test, stack_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Random Forest Accuracy: {rf_acc:.2f}\")\n",
        "print(f\"Logistic Regression Accuracy: {lr_acc:.2f}\")\n",
        "print(f\"Stacking Classifier Accuracy: {stack_acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKNVgBUQJiGf",
        "outputId": "02906392-19dd-4c8f-fa51-34a4aa7103bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.96\n",
            "Logistic Regression Accuracy: 0.96\n",
            "Stacking Classifier Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.\t45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Load the Diabetes dataset\n",
        "data = load_diabetes()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define different max_samples values to test\n",
        "max_samples_values = [0.3, 0.6, 1.0]\n",
        "\n",
        "# Dictionary to store metrics for each max_samples value\n",
        "metrics = {}\n",
        "\n",
        "# Train and evaluate Bagging Regressor for each max_samples value\n",
        "for max_samples in max_samples_values:\n",
        "    # Initialize Bagging Regressor with DecisionTreeRegressor\n",
        "    bagging = BaggingRegressor(\n",
        "        estimator=DecisionTreeRegressor(random_state=42),\n",
        "        n_estimators=10,\n",
        "        max_samples=max_samples,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    bagging.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = bagging.predict(X_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    metrics[max_samples] = {\n",
        "        'MSE': mean_squared_error(y_test, y_pred),\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'R2': r2_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "# Print performance comparison\n",
        "print(\"Performance Comparison of Bagging Regressor with Different max_samples:\")\n",
        "for max_samples in max_samples_values:\n",
        "    print(f\"\\nmax_samples = {max_samples}:\")\n",
        "    print(f\"MSE: {metrics[max_samples]['MSE']:.4f}\")\n",
        "    print(f\"MAE: {metrics[max_samples]['MAE']:.4f}\")\n",
        "    print(f\"R2 Score: {metrics[max_samples]['R2']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djio1CI9JujG",
        "outputId": "6413c09d-3bd7-45c8-cea9-84c88c7b2242"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Comparison of Bagging Regressor with Different max_samples:\n",
            "\n",
            "max_samples = 0.3:\n",
            "MSE: 3173.6067\n",
            "MAE: 45.6225\n",
            "R2 Score: 0.4010\n",
            "\n",
            "max_samples = 0.6:\n",
            "MSE: 3068.3825\n",
            "MAE: 45.4135\n",
            "R2 Score: 0.4209\n",
            "\n",
            "max_samples = 1.0:\n",
            "MSE: 3256.9618\n",
            "MAE: 46.1326\n",
            "R2 Score: 0.3853\n"
          ]
        }
      ]
    }
  ]
}